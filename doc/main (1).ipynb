{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8418fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 11:06:17.786435: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c7d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04bab8",
   "metadata": {},
   "source": [
    "## 1. Load the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df72981",
   "metadata": {},
   "source": [
    "For the project, we provide a training set with 50000 images in the directory `../data/images/` with:\n",
    "- noisy labels for all images provided in `../data/noisy_label.csv`;\n",
    "- clean labels for the first 10000 images provided in `../data/clean_labels.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2df78560",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "../data/clean_labels.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m imgs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_img,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#for i in range(n_img):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#img_fn = f'../data/images/{i+1:05d}.png'\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# load the labels\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m clean_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/clean_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m noisy_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mgenfromtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/noisy_labels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:1977\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1977\u001b[0m     fid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m   1978\u001b[0m     fid_ctx \u001b[38;5;241m=\u001b[39m contextlib\u001b[38;5;241m.\u001b[39mclosing(fid)\n\u001b[1;32m   1979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mopen(path, mode, encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ../data/clean_labels.csv not found."
     ]
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "# load the images\n",
    "n_img = 50000\n",
    "n_noisy = 40000\n",
    "n_clean_noisy = n_img - n_noisy\n",
    "imgs = np.empty((n_img,32,32,3))\n",
    "for i in range(n_img):\n",
    "    img_fn = f'../data/images/{i+1:05d}.png'\n",
    "    imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load the labels\n",
    "clean_labels = np.genfromtxt('../data/clean_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "noisy_labels = np.genfromtxt('../data/noisy_labels.csv', delimiter=',', dtype=\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb169bbc",
   "metadata": {},
   "source": [
    "For illustration, we present a small subset (of size 8) of the images with their clean and noisy labels in `clean_noisy_trainset`. You are encouraged to explore more characteristics of the label noises on the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540ff033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean labels:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# print clean labels\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClean labels:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%5s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m classes[clean_labels[j]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print noisy labels\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoisy labels:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# print clean labels\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClean labels:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%5s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m classes[clean_labels[j]] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print noisy labels\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoisy labels:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_labels' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(2,4,1)\n",
    "ax1.imshow(imgs[0]/255)\n",
    "ax2 = fig.add_subplot(2,4,2)\n",
    "ax2.imshow(imgs[1]/255)\n",
    "ax3 = fig.add_subplot(2,4,3)\n",
    "ax3.imshow(imgs[2]/255)\n",
    "ax4 = fig.add_subplot(2,4,4)\n",
    "ax4.imshow(imgs[3]/255)\n",
    "ax1 = fig.add_subplot(2,4,5)\n",
    "ax1.imshow(imgs[4]/255)\n",
    "ax2 = fig.add_subplot(2,4,6)\n",
    "ax2.imshow(imgs[5]/255)\n",
    "ax3 = fig.add_subplot(2,4,7)\n",
    "ax3.imshow(imgs[6]/255)\n",
    "ax4 = fig.add_subplot(2,4,8)\n",
    "ax4.imshow(imgs[7]/255)\n",
    "\n",
    "# The class-label correspondence\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# print clean labels\n",
    "print('Clean labels:')\n",
    "print(' '.join('%5s' % classes[clean_labels[j]] for j in range(8)))\n",
    "# print noisy labels\n",
    "print('Noisy labels:')\n",
    "print(' '.join('%5s' % classes[noisy_labels[j]] for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7d000",
   "metadata": {},
   "source": [
    "## 2. The predictive model\n",
    "\n",
    "We consider a baseline model directly on the noisy dataset without any label corrections. RGB histogram features are extracted to fit a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd8252",
   "metadata": {},
   "source": [
    "### 2.1. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cae935f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noisy_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_img):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# The target vector consists of noisy labels\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     target_vec[i] \u001b[38;5;241m=\u001b[39m noisy_labels[i]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Use the numbers of pixels in each bin for all three channels as the features\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     feature1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(imgs[i][:,:,\u001b[38;5;241m0\u001b[39m],bins\u001b[38;5;241m=\u001b[39mbins)[\u001b[38;5;241m0\u001b[39m] \n",
      "\u001b[0;31mNameError\u001b[0m: name 'noisy_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# RGB histogram dataset construction\n",
    "no_bins = 6\n",
    "bins = np.linspace(0,255,no_bins) # the range of the rgb histogram\n",
    "target_vec = np.empty(n_img)\n",
    "feature_mtx = np.empty((n_img,3*(len(bins)-1)))\n",
    "i = 0\n",
    "for i in range(n_img):\n",
    "    # The target vector consists of noisy labels\n",
    "    target_vec[i] = noisy_labels[i]\n",
    "    \n",
    "    # Use the numbers of pixels in each bin for all three channels as the features\n",
    "    feature1 = np.histogram(imgs[i][:,:,0],bins=bins)[0] \n",
    "    feature2 = np.histogram(imgs[i][:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(imgs[i][:,:,2],bins=bins)[0]\n",
    "    \n",
    "    # Concatenate three features\n",
    "    feature_mtx[i,] = np.concatenate((feature1, feature2, feature3), axis=None)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# Train a logistic regression model \n",
    "clf = LogisticRegression(random_state=0).fit(feature_mtx, target_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b2ce3",
   "metadata": {},
   "source": [
    "For the convenience of evaluation, we write the following function `predictive_model` that does the label prediction. **For your predictive model, feel free to modify the function, but make sure the function takes an RGB image of numpy.array format with dimension $32\\times32\\times3$  as input, and returns one single label as output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4bf4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def baseline_model(image):\n",
    "    '''\n",
    "    This is the baseline predictive model that takes in the image and returns a label prediction\n",
    "    '''\n",
    "    feature1 = np.histogram(image[:,:,0],bins=bins)[0]\n",
    "    feature2 = np.histogram(image[:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(image[:,:,2],bins=bins)[0]\n",
    "    feature = np.concatenate((feature1, feature2, feature3), axis=None).reshape(1,-1)\n",
    "    return clf.predict(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6dbd8",
   "metadata": {},
   "source": [
    "### 2.2. Model I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d513150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicoletteauld-griffith/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clean_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m---> 13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(imgs[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10000\u001b[39m], clean_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# [BUILD A MORE SOPHISTICATED PREDICTIVE MODEL]\n",
    "\n",
    "# write your code here...\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs[0:10000], clean_labels, test_size=0.3, random_state=42)\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "print(test_acc)\n",
    "\n",
    "def model_I(image):\n",
    "    '''\n",
    "    This function should takes in the image of dimension 32*32*3 as input and returns a label prediction\n",
    "    '''\n",
    "    # write your code here...\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return np.argmax(model.predict(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d722f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e503f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imgs[0:10000], clean_labels, test_size=0.3, random_state=42)\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27571870",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a06655",
   "metadata": {},
   "source": [
    "### 2.3. Model II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eec587-bf7f-45bf-946f-17134f3e5733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ADD WEAKLY SUPERVISED LEARNING FEATURE TO MODEL I]\n",
    "\n",
    "# write your code here...\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "#global average pooling layer for weakly supervised learning\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe49d9c3-90e7-4e3d-b367-5cf99285700e",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imgs[0:10000], clean_labels, test_size=0.3, random_state=42)\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "#evaluation\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "#plot\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "def model_II(image):\n",
    "    '''\n",
    "    This function should takes in the image of dimension 32*32*3 as input and returns a label prediction\n",
    "    '''\n",
    "    # write your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d767be5",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8db1f87",
   "metadata": {},
   "source": [
    "For assessment, we will evaluate your final model on a hidden test dataset with clean labels by the `evaluation` function defined as follows. Although you will not have the access to the test set, the function would be useful for the model developments. For example, you can split the small training set, using one portion for weakly supervised learning and the other for validation purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "def evaluation(model, test_labels, test_imgs):\n",
    "    y_true = test_labels\n",
    "    y_pred = []\n",
    "    for image in test_imgs:\n",
    "        y_pred.append(model(image))\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# This is the code for evaluating the prediction performance on a testset\n",
    "# You will get an error if running this cell, as you do not have the testset\n",
    "# Nonetheless, you can create your own validation set to run the evlauation\n",
    "n_test = 10000\n",
    "test_labels = np.genfromtxt('../data/test_labels.csv', delimiter=',', dtype=\"int8\")\n",
    "test_imgs = np.empty((n_test,32,32,3))\n",
    "for i in range(n_test):\n",
    "    img_fn = f'../data/test_images/test{i+1:05d}.png'\n",
    "    test_imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
    "evaluation(baseline_model, test_labels, test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed1ffc",
   "metadata": {},
   "source": [
    "The overall accuracy is $0.24$, which is better than random guess (which should have a accuracy around $0.10$). For the project, you should try to improve the performance by the following strategies:\n",
    "\n",
    "- Consider a better choice of model architectures, hyperparameters, or training scheme for the predictive model;\n",
    "- Use both `clean_noisy_trainset` and `noisy_trainset` for model training via **weakly supervised learning** methods. One possible solution is to train a \"label-correction\" model using the former, correct the labels in the latter, and train the final predictive model using the corrected dataset.\n",
    "- Apply techniques such as $k$-fold cross validation to avoid overfitting;\n",
    "- Any other reasonable strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ca6d6-d884-4beb-a805-37366c703558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
